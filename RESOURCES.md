# Resources

These resources are work in progress and will be updated.

## Table of Contents
1. [Online Resources for Getting Started With Deep Learning](#Online-Resources-for-Getting-Started-With-Deep-Learning)
2. [Collaborative Projects](#Collaborative-Projects)
3. [Adversarial Examples Code and Experimentation](#Adversarial-Examples-Code-and-Experimentation)
4. [Fooling Humans](#Fooling-Humans)

---
## Online Resources for Getting Started With Deep Learning
Here are some nice resources. There are many more available online.

### 3Blue1Brown

Four superb introductory videos explaining the mathematics underpinning 
neural networks are here: 
[3Blue1Brown Deep Learning](https://www.youtube.com/watch?v=aircAruvnKk&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)

### Keras and Tensorflow
To get started with Keras and Tensorflow, the online documentation provides excellent tutorials
[Keras docs](https://keras.io/#you-have-just-found-keras)


### Andrew Ng’s Coursera course

For a complete introduction to all things ML, this is a fantastic course [https://www.coursera.org/learn/machine-learning]().

---
## Collaborative Projects

### Cleverhans 
An open source library for the development of attacks and associated defenses 
with the aim of benchmarking Machine Learning systems’ vulnerability to adversarial examples.
The code repository for Cleverhans is at [https://github.com/openai/cleverhans]()

### Foolbox
A toolbox for creating adversarial examples to enable testing of defenses.
The documentation for Foolbox is at [https://fool box.readthedocs.io/en/latest/]().

### IBM’s Adversarial Robustness Toolbox
This library includes adversarial attacks, defenses, and detection. 
It also supports robustness metrics measurements. 
The code repository for this library is here: [https://github.com/IBM/ adversarial-robustness-toolbox]().

### RobustML 
Robust ML aims to provide a central website for learning about defenses and their analyses and evaluations. 
It is located at [https://www.robust-ml.org/]().

### Competitions
Several competitions have encouraged participation in the generation of adversarial 
attacks and defenses including competitions from Google 
and Kaggle ([https://www.kaggle.com]()).
 
---
## Adversarial Examples Code and Experimentation

Many research papers have associated GitHub repositories and videos/audio examples. Here are a few.

### Creating Robust examples

Here's a well presented [Jupyter notebook](https://www.anishathalye.com/2017/07/25/synthesizing-adversarial-examples/) to accompany the paper 
[Synthesizing Robust Adversarial Examples by Anthalye et al.](https://arxiv.org/abs/1707.07397).

### Adversarial Patch

To see adversarial patches in action, take a look at this video:
[Adversarial Patch on YouTube](https://www.youtube.com/watch?v=i1sp4X57TL4&feature=youtu.be).
This accompanies the paper [Adversarial Patch by Brown et al.](https://arxiv.org/abs/1712.09665).
Example code for creating adversarial patches is [here](https://github.com/tensorflow/cleverhans/tree/master/examples/adversarial_patch)

### Adversarial Audio 

If you'd like to listen to some adversarial audio examples, take a look [here](https://nicholas.carlini.com/code/audio_adversarial_examples/).
This accompanies the paper [Audi Adversarial Examples Targeted Attacks on Speech-to-Text
by Carlini and Wagner](https://nicholas.carlini.com/papers/2018_dls_audioadvex.pdf)


## Fooling Humans

Humans perception can be tricked in many different ways. Here are some fun examples:

*  [Your brain hallucinates your conscious reality (A. Seth)](https://www.ted.com/talks/anil_seth_how_your_brain_hallucinates_your_conscious_reality)
is an interesting Ted Talk examining how much os what we perceive comes from within.

*  [Everything you hear on a film is a lie (T. Frantzolaz)](https://www.ted.com/talks/tasos_frantzolas_everything_you_hear_on_film_is_a_lie) explains
how we combine multi-sensory input to understand the world.

*  [BBC Two, Try The McGurk Effect! - Horizon: Is Seeing Believing?](https://www.youtube.com/watch?v=G-lN8vWm3m0) shows how 
you can be fooled by conflicting audio and optical input - even when you know you are being tricked. 

*  [Optical Illusions for Kids](https://www.optics4kids.org/illusions) for some basic optical illusions.
